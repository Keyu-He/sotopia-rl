{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import rich\n",
    "with open(\"sotopia_pi_bc_episodes_reward_direct_default_no_goal_gpt-4o.json\", 'r') as f:\n",
    "    direct_default = json.load(f)\n",
    "print(len(direct_default))\n",
    "with open(\"sotopia_pi_bc_episodes_reward_only_response_no_goal_gpt-4o.json\", 'r') as f:\n",
    "    response_only = json.load(f)\n",
    "print(len(response_only))\n",
    "with open(\"sotopia_pi_bc_episodes_reward_utterance_quality_no_goal_gpt-4o.json\", 'r') as f:\n",
    "    utterance_quality = json.load(f)\n",
    "print(len(utterance_quality))\n",
    "with open(\"sotopia_pi_bc_episodes_reward_direct_normalized_no_goal_gpt-4o.json\", 'r') as f:\n",
    "    direct_normalized = json.load(f)\n",
    "print(len(direct_normalized))\n",
    "\n",
    "with open(\"before_3_24/sotopia_pi_bc_episodes_reward_direct_default_gpt-4o.json\") as f:\n",
    "    old_direct_default = json.load(f)\n",
    "print(len(old_direct_default))\n",
    "with open(\"before_3_24/sotopia_pi_bc_episodes_reward_only_response_gpt-4o.json\") as f:\n",
    "    old_response_only = json.load(f)\n",
    "print(len(old_response_only))\n",
    "with open(\"before_3_24/sotopia_pi_bc_episodes_reward_utterance_quality_gpt-4o.json\") as f:\n",
    "    old_utterance_quality = json.load(f)\n",
    "print(len(old_utterance_quality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(direct_default))\n",
    "print(len(response_only))\n",
    "print(len(utterance_quality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_default_rewards = [d[\"value\"] for d in direct_default]\n",
    "response_only_rewards = [d[\"value\"] for d in response_only]\n",
    "utterance_quality_rewards = [d[\"value\"] for d in utterance_quality]\n",
    "direct_normalized_rewards = [d[\"value\"] for d in direct_normalized]\n",
    "old_direct_default_rewards = [d[\"value\"] for d in old_direct_default]\n",
    "old_response_only_rewards = [d[\"value\"] for d in old_response_only]\n",
    "old_utterance_quality_rewards = [d[\"value\"] for d in old_utterance_quality]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_6_buckets(counter, title):\n",
    "    # plot 6 buckets: -inf to 0, 0 to 2, 2 to 4, 4 to 6, 6 to 8, 8 to 10\n",
    "    print(title)\n",
    "    print(\"bucket\\tcount\")\n",
    "    count = sum([v for k, v in counter.items() if k < 0])\n",
    "    print(\"-inf to 0\\t\", count)\n",
    "    for i in range(5):\n",
    "        count = sum([v for k, v in counter.items() if i*2 <= k < (i+1)*2])\n",
    "        print(f\"{i*2} to {(i+1)*2}\\t{count}\")\n",
    "    count = sum([v for k, v in counter.items() if k > 10])\n",
    "    print(\"10 to inf\", count)\n",
    "    print(sum([v for k, v in counter.items()]), \"total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "direct_default_rewards_counter = Counter(direct_default_rewards)\n",
    "response_only_rewards_counter = Counter(response_only_rewards)\n",
    "utterance_quality_rewards_counter = Counter(utterance_quality_rewards)\n",
    "direct_normalized_rewards_counter = Counter(direct_normalized_rewards)\n",
    "old_direct_default_rewards_counter = Counter(old_direct_default_rewards)\n",
    "old_response_only_rewards_counter = Counter(old_response_only_rewards)\n",
    "old_utterance_quality_rewards_counter = Counter(old_utterance_quality_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash(input, output):\n",
    "    return f\"{input}->{output}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_default_map = {get_hash(d[\"input\"], d[\"output\"]): d[\"value\"] for d in direct_default}\n",
    "response_only_map = {get_hash(d[\"input\"], d[\"output\"]): d[\"value\"] for d in response_only}\n",
    "utterance_quality_map = {get_hash(d[\"input\"], d[\"output\"]): d[\"value\"] for d in utterance_quality}\n",
    "direct_normalized_map = {get_hash(d[\"input\"], d[\"output\"]): d[\"value\"] for d in direct_normalized}\n",
    "old_direct_default_map = {get_hash(d[\"input\"], d[\"output\"]): d[\"value\"] for d in old_direct_default}\n",
    "old_response_only_map = {get_hash(d[\"input\"], d[\"output\"]): d[\"value\"] for d in old_response_only}\n",
    "old_utterance_quality_map = {get_hash(d[\"input\"], d[\"output\"]): d[\"value\"] for d in old_utterance_quality}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def calculate_correlation(map1, map2):\n",
    "    # Find common keys between the two maps\n",
    "    common_keys = set(map1.keys()).intersection(map2.keys())\n",
    "    if not common_keys:\n",
    "        raise ValueError(\"No common keys found between the two maps.\")\n",
    "\n",
    "    # Extract the corresponding values from both maps\n",
    "    values1 = np.array([map1[k] for k in common_keys])\n",
    "    values2 = np.array([map2[k] for k in common_keys])\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient and p-value\n",
    "    correlation, p_value = pearsonr(values1, values2)\n",
    "    return correlation, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_difference(map1, map2):\n",
    "    # Find common keys between the two maps\n",
    "    common_keys = set(map1.keys()).intersection(map2.keys())\n",
    "    if not common_keys:\n",
    "        raise ValueError(\"No common keys found between the two maps.\")\n",
    "\n",
    "    # Extract the corresponding values from both maps\n",
    "    values1 = np.array([map1[k] for k in common_keys])\n",
    "    values2 = np.array([map2[k] for k in common_keys])\n",
    "    \n",
    "    # Calculate average difference\n",
    "    average_difference = np.mean(np.abs(values1 - values2))\n",
    "    return average_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_correlation(direct_default_map, old_direct_default_map))\n",
    "print(calculate_average_difference(direct_default_map, old_direct_default_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_correlation(response_only_map, old_response_only_map))\n",
    "print(calculate_average_difference(response_only_map, old_response_only_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_correlation(utterance_quality_map, old_utterance_quality_map))\n",
    "print(calculate_average_difference(utterance_quality_map, old_utterance_quality_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_correlation(direct_normalized_map, direct_default_map))\n",
    "print(calculate_average_difference(direct_normalized_map, direct_default_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_correlation(direct_normalized_map, old_direct_default_map))\n",
    "print(calculate_average_difference(direct_normalized_map, old_direct_default_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_values = []\n",
    "for key, value in old_utterance_quality_map.items():\n",
    "    if value == 10:\n",
    "        new_values.append(utterance_quality_map[key])\n",
    "print(Counter(new_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_values = []\n",
    "for key, value in utterance_quality_map.items():\n",
    "    if value == 10:\n",
    "        new_values.append(old_utterance_quality_map[key])\n",
    "print(Counter(new_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_values = []\n",
    "for key, value in response_only_map.items():\n",
    "    if value == 10:\n",
    "        new_values.append(response_only_map[key])\n",
    "print(Counter(new_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"sft_round_1_bc_data_top_2.json\", 'r') as f:\n",
    "    new_sft = json.load(f)\n",
    "print(len(new_sft))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sotopia-rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
